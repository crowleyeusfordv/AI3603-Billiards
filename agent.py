"""
agent.py - Agent å†³ç­–æ¨¡å—

å®šä¹‰ Agent åŸºç±»å’Œå…·ä½“å®ç°ï¼š
- Agent: åŸºç±»ï¼Œå®šä¹‰å†³ç­–æ¥å£
- BasicAgent: åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„å‚è€ƒå®ç°
- NewAgent: å­¦ç”Ÿè‡ªå®šä¹‰å®ç°æ¨¡æ¿
- analyze_shot_for_reward: å‡»çƒç»“æœè¯„åˆ†å‡½æ•°
"""

import math
import pooltool as pt
import numpy as np
from pooltool.objects import PocketTableSpecs, Table, TableType
import copy
import os
from datetime import datetime
import random
# from poolagent.pool import Pool as CuetipEnv, State as CuetipState
# from poolagent import FunctionAgent

from bayes_opt import BayesianOptimization, SequentialDomainReductionTransformer
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern


def analyze_shot_for_reward(shot: pt.System, last_state: dict, player_targets: list):
    """
    åˆ†æå‡»çƒç»“æœå¹¶è®¡ç®—å¥–åŠ±åˆ†æ•°
    
    å‚æ•°ï¼š
        shot: å·²å®Œæˆç‰©ç†æ¨¡æ‹Ÿçš„ System å¯¹è±¡
        last_state: å‡»çƒå‰çš„çƒçŠ¶æ€ï¼Œ{ball_id: Ball}
        player_targets: å½“å‰ç©å®¶ç›®æ ‡çƒIDï¼Œ['1', '2', ...]
    
    è¿”å›ï¼š
        float: å¥–åŠ±åˆ†æ•°
            +50/çƒï¼ˆå·±æ–¹è¿›çƒï¼‰, +100ï¼ˆåˆæ³•é»‘8ï¼‰, +10ï¼ˆåˆæ³•æ— è¿›çƒï¼‰
            -100ï¼ˆç™½çƒè¿›è¢‹ï¼‰, -150ï¼ˆéæ³•é»‘8ï¼‰, -30ï¼ˆé¦–çƒ/ç¢°åº“çŠ¯è§„ï¼‰
    """
    
    # 1. åŸºæœ¬åˆ†æ
    new_pocketed = [bid for bid, b in shot.balls.items() if b.state.s == 4 and last_state[bid].state.s != 4]
    
    own_pocketed = [bid for bid in new_pocketed if bid in player_targets]
    enemy_pocketed = [bid for bid in new_pocketed if bid not in player_targets and bid not in ["cue", "8"]]
    
    cue_pocketed = "cue" in new_pocketed
    eight_pocketed = "8" in new_pocketed

    # 2. åˆ†æé¦–çƒç¢°æ’
    first_contact_ball_id = None
    foul_first_hit = False
    
    for e in shot.events:
        et = str(e.event_type).lower()
        ids = list(e.ids) if hasattr(e, 'ids') else []
        if ('cushion' not in et) and ('pocket' not in et) and ('cue' in ids):
            other_ids = [i for i in ids if i != 'cue']
            if other_ids:
                first_contact_ball_id = other_ids[0]
                break
    
    if first_contact_ball_id is None:
        if len(last_state) > 2:  # åªæœ‰ç™½çƒå’Œ8å·çƒæ—¶ä¸ç®—çŠ¯è§„
             foul_first_hit = True
    else:
        remaining_own_before = [bid for bid in player_targets if last_state[bid].state.s != 4]
        opponent_plus_eight = [bid for bid in last_state.keys() if bid not in player_targets and bid not in ['cue']]
        if ('8' not in opponent_plus_eight):
            opponent_plus_eight.append('8')
            
        if len(remaining_own_before) > 0 and first_contact_ball_id in opponent_plus_eight:
            foul_first_hit = True
    
    # 3. åˆ†æç¢°åº“
    cue_hit_cushion = False
    target_hit_cushion = False
    foul_no_rail = False
    
    for e in shot.events:
        et = str(e.event_type).lower()
        ids = list(e.ids) if hasattr(e, 'ids') else []
        if 'cushion' in et:
            if 'cue' in ids:
                cue_hit_cushion = True
            if first_contact_ball_id is not None and first_contact_ball_id in ids:
                target_hit_cushion = True

    if len(new_pocketed) == 0 and first_contact_ball_id is not None and (not cue_hit_cushion) and (not target_hit_cushion):
        foul_no_rail = True
        
    # è®¡ç®—å¥–åŠ±åˆ†æ•°
    score = 0
    
    if cue_pocketed and eight_pocketed:
        score -= 150
    elif cue_pocketed:
        score -= 100
    elif eight_pocketed:
        is_targeting_eight_ball_legally = (len(player_targets) == 1 and player_targets[0] == "8")
        score += 100 if is_targeting_eight_ball_legally else -150
            
    if foul_first_hit:
        score -= 30
    if foul_no_rail:
        score -= 30
        
    score += len(own_pocketed) * 50
    score -= len(enemy_pocketed) * 20
    
    if score == 0 and not cue_pocketed and not eight_pocketed and not foul_first_hit and not foul_no_rail:
        score = 10
        
    return score

class Agent():
    """Agent åŸºç±»"""
    def __init__(self):
        pass
    
    def decision(self, *args, **kwargs):
        """å†³ç­–æ–¹æ³•ï¼ˆå­ç±»éœ€å®ç°ï¼‰
        
        è¿”å›ï¼šdict, åŒ…å« 'V0', 'phi', 'theta', 'a', 'b'
        """
        pass
    
    def _random_action(self,):
        """ç”Ÿæˆéšæœºå‡»çƒåŠ¨ä½œ
        
        è¿”å›ï¼šdict
            V0: [0.5, 8.0] m/s
            phi: [0, 360] åº¦
            theta: [0, 90] åº¦
            a, b: [-0.5, 0.5] çƒåŠå¾„æ¯”ä¾‹
        """
        action = {
            'V0': round(random.uniform(0.5, 8.0), 2),   # åˆé€Ÿåº¦ 0.5~8.0 m/s
            'phi': round(random.uniform(0, 360), 2),    # æ°´å¹³è§’åº¦ (0Â°~360Â°)
            'theta': round(random.uniform(0, 90), 2),   # å‚ç›´è§’åº¦
            'a': round(random.uniform(-0.5, 0.5), 3),   # æ†å¤´æ¨ªå‘åç§»ï¼ˆå•ä½ï¼šçƒåŠå¾„æ¯”ä¾‹ï¼‰
            'b': round(random.uniform(-0.5, 0.5), 3)    # æ†å¤´çºµå‘åç§»
        }
        return action



class BasicAgent(Agent):
    """åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ™ºèƒ½ Agent"""
    
    def __init__(self, target_balls=None):
        """åˆå§‹åŒ– Agent
        
        å‚æ•°ï¼š
            target_balls: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨
        """
        super().__init__()
        
        # æœç´¢ç©ºé—´
        self.pbounds = {
            'V0': (0.5, 8.0),
            'phi': (0, 360),
            'theta': (0, 90), 
            'a': (-0.5, 0.5),
            'b': (-0.5, 0.5)
        }
        
        # ä¼˜åŒ–å‚æ•°
        self.INITIAL_SEARCH = 20
        self.OPT_SEARCH = 10
        self.ALPHA = 1e-2
        
        # æ¨¡æ‹Ÿå™ªå£°ï¼ˆå¯è°ƒæ•´ä»¥æ”¹å˜è®­ç»ƒéš¾åº¦ï¼‰
        self.noise_std = {
            'V0': 0.1,
            'phi': 0.1,
            'theta': 0.1,
            'a': 0.003,
            'b': 0.003
        }
        self.enable_noise = False
        
        print("BasicAgent (Smart, pooltool-native) å·²åˆå§‹åŒ–ã€‚")

    
    def _create_optimizer(self, reward_function, seed):
        """åˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨
        
        å‚æ•°ï¼š
            reward_function: ç›®æ ‡å‡½æ•°ï¼Œ(V0, phi, theta, a, b) -> score
            seed: éšæœºç§å­
        
        è¿”å›ï¼š
            BayesianOptimizationå¯¹è±¡
        """
        gpr = GaussianProcessRegressor(
            kernel=Matern(nu=2.5),
            alpha=self.ALPHA,
            n_restarts_optimizer=10,
            random_state=seed
        )
        
        bounds_transformer = SequentialDomainReductionTransformer(
            gamma_osc=0.8,
            gamma_pan=1.0
        )
        
        optimizer = BayesianOptimization(
            f=reward_function,
            pbounds=self.pbounds,
            random_state=seed,
            verbose=0,
            bounds_transformer=bounds_transformer
        )
        optimizer._gp = gpr
        
        return optimizer


    def decision(self, balls=None, my_targets=None, table=None):
        """ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æœç´¢æœ€ä½³å‡»çƒå‚æ•°
        
        å‚æ•°ï¼š
            balls: çƒçŠ¶æ€å­—å…¸ï¼Œ{ball_id: Ball}
            my_targets: ç›®æ ‡çƒIDåˆ—è¡¨ï¼Œ['1', '2', ...]
            table: çƒæ¡Œå¯¹è±¡
        
        è¿”å›ï¼š
            dict: å‡»çƒåŠ¨ä½œ {'V0', 'phi', 'theta', 'a', 'b'}
                å¤±è´¥æ—¶è¿”å›éšæœºåŠ¨ä½œ
        """
        if balls is None:
            print(f"[BasicAgent] Agent decisionå‡½æ•°æœªæ”¶åˆ°ballså…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚")
            return self._random_action()
        try:
            
            # ä¿å­˜ä¸€ä¸ªå‡»çƒå‰çš„çŠ¶æ€å¿«ç…§ï¼Œç”¨äºå¯¹æ¯”
            last_state_snapshot = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}

            remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
            if len(remaining_own) == 0:
                my_targets = ["8"]
                print("[BasicAgent] æˆ‘çš„ç›®æ ‡çƒå·²å…¨éƒ¨æ¸…ç©ºï¼Œè‡ªåŠ¨åˆ‡æ¢ç›®æ ‡ä¸ºï¼š8å·çƒ")

            # 1.åŠ¨æ€åˆ›å»ºâ€œå¥–åŠ±å‡½æ•°â€ (Wrapper)
            # è´å¶æ–¯ä¼˜åŒ–å™¨ä¼šè°ƒç”¨æ­¤å‡½æ•°ï¼Œå¹¶ä¼ å…¥å‚æ•°
            def reward_fn_wrapper(V0, phi, theta, a, b):
                # åˆ›å»ºä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿçš„æ²™ç›’ç³»ç»Ÿ
                sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
                sim_table = copy.deepcopy(table)
                cue = pt.Cue(cue_ball_id="cue")

                shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
                
                try:
                    if self.enable_noise:
                        V0_noisy = V0 + np.random.normal(0, self.noise_std['V0'])
                        phi_noisy = phi + np.random.normal(0, self.noise_std['phi'])
                        theta_noisy = theta + np.random.normal(0, self.noise_std['theta'])
                        a_noisy = a + np.random.normal(0, self.noise_std['a'])
                        b_noisy = b + np.random.normal(0, self.noise_std['b'])
                        
                        V0_noisy = np.clip(V0_noisy, 0.5, 8.0)
                        phi_noisy = phi_noisy % 360
                        theta_noisy = np.clip(theta_noisy, 0, 90)
                        a_noisy = np.clip(a_noisy, -0.5, 0.5)
                        b_noisy = np.clip(b_noisy, -0.5, 0.5)
                        
                        shot.cue.set_state(V0=V0_noisy, phi=phi_noisy, theta=theta_noisy, a=a_noisy, b=b_noisy)
                    else:
                        shot.cue.set_state(V0=V0, phi=phi, theta=theta, a=a, b=b)
                    
                    # å…³é”®ï¼šä½¿ç”¨ pooltool ç‰©ç†å¼•æ“ (ä¸–ç•ŒA)
                    try:
                        pt.simulate(shot, inplace=True, max_events=200)
                    except Exception:
                        return -500
                except Exception as e:
                    # æ¨¡æ‹Ÿå¤±è´¥ï¼Œç»™äºˆæå¤§æƒ©ç½š
                    return -500
                
                # ä½¿ç”¨æˆ‘ä»¬çš„â€œè£åˆ¤â€æ¥æ‰“åˆ†
                score = analyze_shot_for_reward(
                    shot=shot,
                    last_state=last_state_snapshot,
                    player_targets=my_targets
                )


                return score

            print(f"[BasicAgent] æ­£åœ¨ä¸º Player (targets: {my_targets}) æœç´¢æœ€ä½³å‡»çƒ...")
            
            seed = np.random.randint(1e6)
            optimizer = self._create_optimizer(reward_fn_wrapper, seed)
            optimizer.maximize(
                init_points=self.INITIAL_SEARCH,
                n_iter=self.OPT_SEARCH
            )
            
            best_result = optimizer.max
            best_params = best_result['params']
            best_score = best_result['target']

            if best_score < 10:
                print(f"[BasicAgent] æœªæ‰¾åˆ°å¥½çš„æ–¹æ¡ˆ (æœ€é«˜åˆ†: {best_score:.2f})ã€‚ä½¿ç”¨éšæœºåŠ¨ä½œã€‚")
                return self._random_action()
            action = {
                'V0': float(best_params['V0']),
                'phi': float(best_params['phi']),
                'theta': float(best_params['theta']),
                'a': float(best_params['a']),
                'b': float(best_params['b']),
            }

            print(f"[BasicAgent] å†³ç­– (å¾—åˆ†: {best_score:.2f}): "
                  f"V0={action['V0']:.2f}, phi={action['phi']:.2f}, "
                  f"Î¸={action['theta']:.2f}, a={action['a']:.3f}, b={action['b']:.3f}")
            return action

        except Exception as e:
            print(f"[BasicAgent] å†³ç­–æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚åŸå› : {e}")
            import traceback
            traceback.print_exc()
            return self._random_action()


class NewAgent(Agent):
    """
    Phase 10: The Robust Dominator (ç¨³å¥ç»Ÿæ²»è€…)

    æ ¸å¿ƒçªç ´ï¼š
    1. æŠ—å™ªæµ‹è¯• (Robustness Check): å¼•å…¥è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œå¯¹å€™é€‰åŠ¨ä½œæ·»åŠ ç¯å¢ƒå™ªå£°è¿›è¡Œå¤šæ¬¡éªŒè¯ã€‚
       åªæœ‰åœ¨å™ªå£°ä¸‹ä¾ç„¶ç¨³å®šçš„è¿›çƒè·¯çº¿æ‰ä¼šè¢«é‡‡çº³ï¼Œå½»åº•æ¶ˆé™¤â€œè«åå…¶å¦™æ‰“ä¸¢â€çš„å¤±è¯¯ã€‚
    2. åŠ¨æ€é£é™©è¯„ä¼°: å®å¯æ‰“è¿›ç‡ 100% çš„ç®€å•çƒï¼Œä¹Ÿä¸æ‰“è¿›ç‡ 50% çš„ç¥ä»™çƒã€‚
    3. ç»§æ‰¿ Phase 9 çš„æš´åŠ›å¼€çƒä¸é˜²å®ˆé€»è¾‘ã€‚
    """

    def __init__(self):
        super().__init__()
        self.BALL_RADIUS = 0.028575
        # å¿…é¡»ä¸ç¯å¢ƒå™ªå£°ä¿æŒä¸€è‡´ï¼Œç”¨äºè‡ªæˆ‘æµ‹è¯•
        self.noise_std = {
            'V0': 0.1, 'phi': 0.1, 'theta': 0.1, 'a': 0.003, 'b': 0.003
        }
        print("NewAgent (Phase 10) å·²åˆå§‹åŒ– - ç¨³å¥ç»Ÿæ²»æ¨¡å¼")

    def _calculate_angle_degrees(self, v):
        angle = np.degrees(np.arctan2(v[1], v[0]))
        if angle < 0: angle += 360
        return angle

    def get_aim_info(self, target_ball, pocket, cue_ball):
        pos_t = target_ball.state.rvw[0]
        pos_c = cue_ball.state.rvw[0]
        pos_p = pocket.center

        vec_t_p = pos_p - pos_t
        dist_t_p = np.linalg.norm(vec_t_p)
        dir_t_p = vec_t_p / (dist_t_p + 1e-9)
        pos_ghost = pos_t - dir_t_p * (2 * self.BALL_RADIUS)

        vec_c_g = pos_ghost - pos_c
        aim_phi = self._calculate_angle_degrees(vec_c_g)

        vec_c_t = pos_t - pos_c
        cos_theta = np.dot(vec_c_t, vec_t_p) / (np.linalg.norm(vec_c_t) * dist_t_p + 1e-9)
        cut_angle = np.degrees(np.arccos(np.clip(cos_theta, -1, 1)))

        total_dist = np.linalg.norm(vec_c_g) + dist_t_p
        return aim_phi, cut_angle, total_dist

    def check_next_shot_exist(self, balls, my_targets, table):
        """ç®€å•çš„ä¸‹çƒè·¯çº¿æ£€æŸ¥"""
        cue_ball = balls['cue']
        remaining = [bid for bid in my_targets if balls[bid].state.s != 4]
        targets = remaining if remaining else ['8']
        for tid in targets:
            if balls[tid].state.s == 4: continue
            for pid, pocket in table.pockets.items():
                _, cut_angle, _ = self.get_aim_info(balls[tid], pocket, cue_ball)
                if cut_angle < 75: return True
        return False

    def get_break_shot(self, balls):
        """Phase 9 çš„å®Œç¾å¼€çƒ"""
        target = balls['1']
        cue = balls['cue']
        vec = target.state.rvw[0] - cue.state.rvw[0]
        phi = self._calculate_angle_degrees(vec)
        return {'V0': 8.0, 'phi': phi, 'theta': 0, 'a': 0.01, 'b': -0.08}

    def simulate_with_noise(self, shot_params, table, balls, n_sims=3):
        """
        æŠ—å™ªæµ‹è¯•æ ¸å¿ƒå‡½æ•°
        å¯¹åŒä¸€ä¸ªåŠ¨ä½œè¿›è¡Œ n_sims æ¬¡å¸¦å™ªå£°çš„æ¨¡æ‹Ÿï¼Œè¿”å›æˆåŠŸè¿›çƒçš„æ¬¡æ•°å’Œå¹³å‡åˆ†
        """
        success_count = 0
        total_score = 0
        min_score = 9999.0

        sim_table = copy.deepcopy(table)

        for _ in range(n_sims):
            # æ·»åŠ å™ªå£°
            noisy_action = {
                'V0': shot_params['V0'] + np.random.normal(0, self.noise_std['V0']),
                'phi': shot_params['phi'] + np.random.normal(0, self.noise_std['phi']),
                'theta': 0,
                'a': shot_params.get('a', 0) + np.random.normal(0, self.noise_std['a']),
                'b': shot_params.get('b', 0) + np.random.normal(0, self.noise_std['b'])
            }

            # é™åˆ¶èŒƒå›´
            noisy_action['V0'] = np.clip(noisy_action['V0'], 0.1, 8.0)

            # æ¨¡æ‹Ÿ
            sim_balls = {k: copy.deepcopy(v) for k, v in balls.items()}
            cue = pt.Cue(cue_ball_id="cue")
            shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
            shot.cue.set_state(**noisy_action)

            # å¿…é¡»åŠ  max_events=200 é˜²æ­¢æ­»é”
            try:
                pt.simulate(shot, inplace=True, max_events=200)
            except:
                # å¦‚æœæ¨¡æ‹Ÿå¡æ­»ï¼Œç›´æ¥åˆ¤ä¸ºæå·®
                return 0, -5000, -5000

            # è¯„åˆ† (ç®€åŒ–çš„å•æ¬¡è¯„åˆ†)
            score = 0
            new_pocketed = [bid for bid, b in sim_balls.items() if b.state.s == 4 and balls[bid].state.s != 4]
            cue_potted = 'cue' in new_pocketed
            eight_potted = '8' in new_pocketed
            target_potted = shot_params['target'] in new_pocketed

            # ç”Ÿæ­»åˆ¤å®š
            is_shooting_8 = (shot_params['target'] == '8')

            if eight_potted:
                if not is_shooting_8 or cue_potted:
                    score = -5000;  # åˆ¤è´Ÿ
                else:
                    score = 5000;  # èµ¢äº†
            elif cue_potted:
                score = -2000  # æ´—è¢‹
            elif target_potted:
                score = 100
                score -= shot_params['cut'] * 0.2
            else:
                score = -50
                # æ²¡è¿›çƒæ—¶çš„é˜²å®ˆæ£€æŸ¥ç•¥è¿‡ï¼Œä¸»è¦çœ‹èƒ½ä¸èƒ½è¿›

            total_score += score
            if score < min_score: min_score = score

            # ç»Ÿè®¡æˆåŠŸè¿›çƒæ¬¡æ•° (ä¸ç®—é»‘8åˆ¤è´Ÿçš„æƒ…å†µ)
            if target_potted and not cue_potted and not (eight_potted and not is_shooting_8):
                success_count += 1

        return success_count, total_score / n_sims, min_score

    def decision(self, balls, my_targets, table):
        try:
            cue_ball = balls['cue']

            # 0. å¼€çƒ
            balls_on_table = [b for k, b in balls.items() if k != 'cue' and b.state.s != 4]
            if len(balls_on_table) == 15:
                print("[Robust] ğŸ± å®Œç¾æš´åŠ›å¼€çƒ")
                return self.get_break_shot(balls)

            remaining_targets = [bid for bid in my_targets if balls[bid].state.s != 4]
            is_shooting_8 = len(remaining_targets) == 0
            targets_to_search = remaining_targets if not is_shooting_8 else ['8']

            # 1. è¿›æ”»æµ·é€‰
            candidates = []
            for tid in targets_to_search:
                if balls[tid].state.s == 4: continue
                for pid, pocket in table.pockets.items():
                    aim_phi, cut_angle, dist = self.get_aim_info(balls[tid], pocket, cue_ball)
                    if cut_angle > 82: continue

                    # ç”Ÿæˆå€™é€‰: æ ‡å‡†åŠ› & å°åŠ›
                    v_base = np.clip(2.0 + dist * 2.3, 2.0, 7.5)
                    # ä¼˜å…ˆè€ƒè™‘ä¸­ç­‰åŠ›åº¦ï¼Œæœ€ç¨³
                    candidates.append({'target': tid, 'phi': aim_phi, 'cut': cut_angle, 'V0': v_base})
                    if dist < 1.0:
                        candidates.append(
                            {'target': tid, 'phi': aim_phi, 'cut': cut_angle, 'V0': np.clip(v_base * 0.7, 1.5, 4.0)})
                    # å¤§åŠ›ä¿®æ­£ (é’ˆå¯¹åˆ‡çƒ)
                    if cut_angle < 50:
                        candidates.append(
                            {'target': tid, 'phi': aim_phi, 'cut': cut_angle, 'V0': np.clip(v_base * 1.4, 3.0, 8.0)})

            candidates.sort(key=lambda x: x['cut'])
            top_candidates = candidates[:6]  # åªéªŒè¯å‰6ä¸ª

            best_action = None
            best_robust_score = -99999.0

            # 2. æŠ—å™ªæ¨¡æ‹Ÿ (Robustness Check)
            # å¯¹æ¯ä¸ªå€™é€‰è¿›è¡Œ 3 æ¬¡å¸¦å™ªå£°æ¨¡æ‹Ÿ
            for cand in top_candidates:
                # n_sims=3: æ¨¡æ‹Ÿ3æ¬¡ã€‚å¿…é¡»è‡³å°‘è¿›2æ¬¡æ‰è€ƒè™‘ï¼Œè¿›3æ¬¡æœ€å¥½ã€‚
                success_count, avg_score, min_score = self.simulate_with_noise(cand, table, balls, n_sims=3)

                # è¿‡æ»¤é«˜é£é™©çƒï¼š
                # å¦‚æœ3æ¬¡é‡Œæœ‰1æ¬¡æ´—è¢‹æˆ–åˆ¤è´Ÿ(min_score < -1000)ï¼Œç»å¯¹ä¸æ‰“
                if min_score < -1000: continue

                # ç¨³å®šæ€§è¯„åˆ†ï¼š
                # æˆåŠŸç‡æƒé‡æé«˜ã€‚æˆåŠŸ3æ¬¡ > æˆåŠŸ2æ¬¡ >> æˆåŠŸ1æ¬¡
                robust_score = success_count * 1000 + avg_score

                # èµ°ä½åŠ åˆ† (ä»…å¯¹ç¨³è¿›çš„çƒè®¡ç®—èµ°ä½)
                if success_count >= 2 and not is_shooting_8:
                    # å¿«é€Ÿæ£€æŸ¥ä¸€æ¬¡æ— å™ªå£°çš„èµ°ä½
                    # (ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œè¿™é‡Œä¸å†å¸¦å™ªå£°æ¨¡æ‹Ÿèµ°ä½ï¼ŒåªåŸºäºæ— å™ªå£°å‡ ä½•æ£€æŸ¥)
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šç›´æ¥ç”¨ avg_score é‡Œçš„è·ç¦»/åˆ‡è§’å› å­
                    pass

                if robust_score > best_robust_score:
                    best_robust_score = robust_score
                    best_action = cand
                    # è®°å½•è¯¥åŠ¨ä½œçš„æˆåŠŸç‡ï¼Œç”¨äºæ—¥å¿—
                    best_action['success_rate'] = success_count

            # 3. å†³ç­–é˜ˆå€¼
            # å¦‚æœæœ€ä½³çƒçš„æˆåŠŸç‡ < 2/3 (å³3æ¬¡åªè¿›ä¸åˆ°äº†2æ¬¡)ï¼Œè¯´æ˜å¾ˆä¸ç¨³ï¼Œä¸å¦‚é˜²å®ˆ
            if best_action and best_action['success_rate'] >= 2:
                print(f"[Robust] ğŸ¯ ç¨³å¥è¿›æ”»: {best_action['target']} (ç¨³åº¦:{best_action['success_rate']}/3)")
                return {'V0': best_action['V0'], 'phi': best_action['phi'], 'theta': 0, 'a': 0, 'b': 0}

            # 4. é¡¶çº§é˜²å®ˆ (Elite Safety)
            print("[Robust] ğŸ›¡ï¸ è¿›æ”»é£é™©å¤§ï¼Œæ‰§è¡Œé˜²å®ˆ")
            # æ‰¾æœ€è¿‘çš„çƒï¼Œå°è¯•è¸¢å¼€
            safety_candidates = []
            for tid in targets_to_search:
                if balls[tid].state.s == 4: continue
                dist = np.linalg.norm(balls[tid].state.rvw[0] - cue_ball.state.rvw[0])
                if dist > 1.2: continue  # å¤ªè¿œä¸ç¢°

                vec = balls[tid].state.rvw[0] - cue_ball.state.rvw[0]
                phi = self._calculate_angle_degrees(vec)
                safety_candidates.append({'V0': 3.0, 'phi': phi, 'theta': 0, 'a': 0, 'b': 0})
                safety_candidates.append({'V0': 2.0, 'phi': phi + 2, 'theta': 0, 'a': 0, 'b': 0})
                safety_candidates.append({'V0': 2.0, 'phi': phi - 2, 'theta': 0, 'a': 0, 'b': 0})

            # ç®€å•çš„é˜²å®ˆé€‰æ‹©ï¼šé€‰é‚£ä¸ªè‚¯å®šä¸æ´—è¢‹çš„
            for shot in safety_candidates:
                # å¿«é€Ÿå•æ¬¡éªŒè¯
                success, avg, min_s = self.simulate_with_noise(dict(target='none', cut=0, **shot), table, balls,
                                                               n_sims=1)
                if min_s > -500:  # å®‰å…¨
                    return shot

            return self._random_action()

        except Exception as e:
            print(f"Error: {e}")
            return self._random_action()