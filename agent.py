"""
agent.py - Agent å†³ç­–æ¨¡å—

å®šä¹‰ Agent åŸºç±»å’Œå…·ä½“å®ç°ï¼š
- Agent: åŸºç±»ï¼Œå®šä¹‰å†³ç­–æ¥å£
- BasicAgent: åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„å‚è€ƒå®ç°
- NewAgent: å­¦ç”Ÿè‡ªå®šä¹‰å®ç°æ¨¡æ¿
- analyze_shot_for_reward: å‡»çƒç»“æœè¯„åˆ†å‡½æ•°
"""

import math
import pooltool as pt
import numpy as np
from pooltool.objects import PocketTableSpecs, Table, TableType
import copy
import os
from datetime import datetime
import random
import signal
# from poolagent.pool import Pool as CuetipEnv, State as CuetipState
# from poolagent import FunctionAgent

from bayes_opt import BayesianOptimization, SequentialDomainReductionTransformer
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern

# ============ è¶…æ—¶å®‰å…¨æ¨¡æ‹Ÿæœºåˆ¶ ============
class SimulationTimeoutError(Exception):
    """ç‰©ç†æ¨¡æ‹Ÿè¶…æ—¶å¼‚å¸¸"""
    pass

def _timeout_handler(signum, frame):
    """è¶…æ—¶ä¿¡å·å¤„ç†å™¨"""
    raise SimulationTimeoutError("ç‰©ç†æ¨¡æ‹Ÿè¶…æ—¶")

def simulate_with_timeout(shot, timeout=3):
    """å¸¦è¶…æ—¶ä¿æŠ¤çš„ç‰©ç†æ¨¡æ‹Ÿ
    
    å‚æ•°ï¼š
        shot: pt.System å¯¹è±¡
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3ç§’
    
    è¿”å›ï¼š
        bool: True è¡¨ç¤ºæ¨¡æ‹ŸæˆåŠŸï¼ŒFalse è¡¨ç¤ºè¶…æ—¶æˆ–å¤±è´¥
    
    è¯´æ˜ï¼š
        ä½¿ç”¨ signal.SIGALRM å®ç°è¶…æ—¶æœºåˆ¶ï¼ˆä»…æ”¯æŒ Unix/Linuxï¼‰
        è¶…æ—¶åè‡ªåŠ¨æ¢å¤ï¼Œä¸ä¼šå¯¼è‡´ç¨‹åºå¡æ­»
    """
    # è®¾ç½®è¶…æ—¶ä¿¡å·å¤„ç†å™¨
    old_handler = signal.signal(signal.SIGALRM, _timeout_handler)
    signal.alarm(timeout)  # è®¾ç½®è¶…æ—¶æ—¶é—´
    
    try:
        pt.simulate(shot, inplace=True)
        signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
        return True
    except SimulationTimeoutError:
        print(f"[WARNING] ç‰©ç†æ¨¡æ‹Ÿè¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼‰ï¼Œè·³è¿‡æ­¤æ¬¡æ¨¡æ‹Ÿ")
        return False
    except Exception as e:
        signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
        raise e
    finally:
        signal.signal(signal.SIGALRM, old_handler)  # æ¢å¤åŸå¤„ç†å™¨

# ============================================



def analyze_shot_for_reward(shot: pt.System, last_state: dict, player_targets: list):
    """
    åˆ†æå‡»çƒç»“æœå¹¶è®¡ç®—å¥–åŠ±åˆ†æ•°ï¼ˆå®Œå…¨å¯¹é½å°çƒè§„åˆ™ï¼‰
    
    å‚æ•°ï¼š
        shot: å·²å®Œæˆç‰©ç†æ¨¡æ‹Ÿçš„ System å¯¹è±¡
        last_state: å‡»çƒå‰çš„çƒçŠ¶æ€ï¼Œ{ball_id: Ball}
        player_targets: å½“å‰ç©å®¶ç›®æ ‡çƒIDï¼Œ['1', '2', ...] æˆ– ['8']
    
    è¿”å›ï¼š
        float: å¥–åŠ±åˆ†æ•°
            +50/çƒï¼ˆå·±æ–¹è¿›çƒï¼‰, +100ï¼ˆåˆæ³•é»‘8ï¼‰, +10ï¼ˆåˆæ³•æ— è¿›çƒï¼‰
            -100ï¼ˆç™½çƒè¿›è¢‹ï¼‰, -150ï¼ˆéæ³•é»‘8/ç™½çƒ+é»‘8ï¼‰, -30ï¼ˆé¦–çƒ/ç¢°åº“çŠ¯è§„ï¼‰
    
    è§„åˆ™æ ¸å¿ƒï¼š
        - æ¸…å°å‰ï¼šplayer_targets = ['1'-'7'] æˆ– ['9'-'15']ï¼Œé»‘8ä¸å±äºä»»ä½•äºº
        - æ¸…å°åï¼šplayer_targets = ['8']ï¼Œé»‘8æˆä¸ºå”¯ä¸€ç›®æ ‡çƒ
    """
    
    # 1. åŸºæœ¬åˆ†æ
    new_pocketed = [bid for bid, b in shot.balls.items() if b.state.s == 4 and last_state[bid].state.s != 4]
    
    # æ ¹æ® player_targets åˆ¤æ–­è¿›çƒå½’å±ï¼ˆé»‘8åªæœ‰åœ¨æ¸…å°åæ‰ç®—å·±æ–¹çƒï¼‰
    own_pocketed = [bid for bid in new_pocketed if bid in player_targets]
    enemy_pocketed = [bid for bid in new_pocketed if bid not in player_targets and bid not in ["cue", "8"]]
    
    cue_pocketed = "cue" in new_pocketed
    eight_pocketed = "8" in new_pocketed

    # 2. åˆ†æé¦–çƒç¢°æ’ï¼ˆå®šä¹‰åˆæ³•çš„çƒIDé›†åˆï¼‰
    first_contact_ball_id = None
    foul_first_hit = False
    valid_ball_ids = {'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'}
    
    for e in shot.events:
        et = str(e.event_type).lower()
        ids = list(e.ids) if hasattr(e, 'ids') else []
        if ('cushion' not in et) and ('pocket' not in et) and ('cue' in ids):
            # è¿‡æ»¤æ‰ 'cue' å’Œéçƒå¯¹è±¡ï¼ˆå¦‚ 'cue stick'ï¼‰ï¼Œåªä¿ç•™åˆæ³•çš„çƒID
            other_ids = [i for i in ids if i != 'cue' and i in valid_ball_ids]
            if other_ids:
                first_contact_ball_id = other_ids[0]
                break
    
    # é¦–çƒçŠ¯è§„åˆ¤å®šï¼šå®Œå…¨å¯¹é½ player_targets
    if first_contact_ball_id is None:
        # æœªå‡»ä¸­ä»»ä½•çƒï¼ˆä½†è‹¥åªå‰©ç™½çƒå’Œé»‘8ä¸”å·²æ¸…å°ï¼Œåˆ™ä¸ç®—çŠ¯è§„ï¼‰
        if len(last_state) > 2 or player_targets != ['8']:
            foul_first_hit = True
    else:
        # é¦–æ¬¡å‡»æ‰“çš„çƒå¿…é¡»æ˜¯ player_targets ä¸­çš„çƒ
        if first_contact_ball_id not in player_targets:
            foul_first_hit = True
    
    # 3. åˆ†æç¢°åº“
    cue_hit_cushion = False
    target_hit_cushion = False
    foul_no_rail = False
    
    for e in shot.events:
        et = str(e.event_type).lower()
        ids = list(e.ids) if hasattr(e, 'ids') else []
        if 'cushion' in et:
            if 'cue' in ids:
                cue_hit_cushion = True
            if first_contact_ball_id is not None and first_contact_ball_id in ids:
                target_hit_cushion = True

    if len(new_pocketed) == 0 and first_contact_ball_id is not None and (not cue_hit_cushion) and (not target_hit_cushion):
        foul_no_rail = True
        
    # 4. è®¡ç®—å¥–åŠ±åˆ†æ•°
    score = 0
    
    # ç™½çƒè¿›è¢‹å¤„ç†
    if cue_pocketed and eight_pocketed:
        score -= 150  # ç™½çƒ+é»‘8åŒæ—¶è¿›è¢‹ï¼Œä¸¥é‡çŠ¯è§„
    elif cue_pocketed:
        score -= 100  # ç™½çƒè¿›è¢‹
    elif eight_pocketed:
        # é»‘8è¿›è¢‹ï¼šåªæœ‰æ¸…å°åï¼ˆplayer_targets == ['8']ï¼‰æ‰åˆæ³•
        if player_targets == ['8']:
            score += 100  # åˆæ³•æ‰“è¿›é»‘8
        else:
            score -= 150  # æ¸…å°å‰è¯¯æ‰“é»‘8ï¼Œåˆ¤è´Ÿ
            
    # é¦–çƒçŠ¯è§„å’Œç¢°åº“çŠ¯è§„
    if foul_first_hit:
        score -= 30
    if foul_no_rail:
        score -= 30
        
    # è¿›çƒå¾—åˆ†ï¼ˆown_pocketed å·²æ ¹æ® player_targets æ­£ç¡®åˆ†ç±»ï¼‰
    score += len(own_pocketed) * 50
    score -= len(enemy_pocketed) * 20
    
    # åˆæ³•æ— è¿›çƒå°å¥–åŠ±
    if score == 0 and not cue_pocketed and not eight_pocketed and not foul_first_hit and not foul_no_rail:
        score = 10
        
    return score

class Agent():
    """Agent åŸºç±»"""
    def __init__(self):
        pass
    
    def decision(self, *args, **kwargs):
        """å†³ç­–æ–¹æ³•ï¼ˆå­ç±»éœ€å®ç°ï¼‰
        
        è¿”å›ï¼šdict, åŒ…å« 'V0', 'phi', 'theta', 'a', 'b'
        """
        pass
    
    def _random_action(self,):
        """ç”Ÿæˆéšæœºå‡»çƒåŠ¨ä½œ
        
        è¿”å›ï¼šdict
            V0: [0.5, 8.0] m/s
            phi: [0, 360] åº¦
            theta: [0, 90] åº¦
            a, b: [-0.5, 0.5] çƒåŠå¾„æ¯”ä¾‹
        """
        action = {
            'V0': round(random.uniform(0.5, 8.0), 2),   # åˆé€Ÿåº¦ 0.5~8.0 m/s
            'phi': round(random.uniform(0, 360), 2),    # æ°´å¹³è§’åº¦ (0Â°~360Â°)
            'theta': round(random.uniform(0, 90), 2),   # å‚ç›´è§’åº¦
            'a': round(random.uniform(-0.5, 0.5), 3),   # æ†å¤´æ¨ªå‘åç§»ï¼ˆå•ä½ï¼šçƒåŠå¾„æ¯”ä¾‹ï¼‰
            'b': round(random.uniform(-0.5, 0.5), 3)    # æ†å¤´çºµå‘åç§»
        }
        return action



class BasicAgent(Agent):
    """åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ™ºèƒ½ Agent"""
    
    def __init__(self, target_balls=None):
        """åˆå§‹åŒ– Agent
        
        å‚æ•°ï¼š
            target_balls: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨
        """
        super().__init__()
        
        # æœç´¢ç©ºé—´
        self.pbounds = {
            'V0': (0.5, 8.0),
            'phi': (0, 360),
            'theta': (0, 90), 
            'a': (-0.5, 0.5),
            'b': (-0.5, 0.5)
        }
        
        # ä¼˜åŒ–å‚æ•°
        self.INITIAL_SEARCH = 20
        self.OPT_SEARCH = 10
        self.ALPHA = 1e-2
        
        # æ¨¡æ‹Ÿå™ªå£°ï¼ˆå¯è°ƒæ•´ä»¥æ”¹å˜è®­ç»ƒéš¾åº¦ï¼‰
        self.noise_std = {
            'V0': 0.1,
            'phi': 0.1,
            'theta': 0.1,
            'a': 0.003,
            'b': 0.003
        }
        self.enable_noise = False
        
        print("BasicAgent (Smart, pooltool-native) å·²åˆå§‹åŒ–ã€‚")

    
    def _create_optimizer(self, reward_function, seed):
        """åˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨
        
        å‚æ•°ï¼š
            reward_function: ç›®æ ‡å‡½æ•°ï¼Œ(V0, phi, theta, a, b) -> score
            seed: éšæœºç§å­
        
        è¿”å›ï¼š
            BayesianOptimizationå¯¹è±¡
        """
        gpr = GaussianProcessRegressor(
            kernel=Matern(nu=2.5),
            alpha=self.ALPHA,
            n_restarts_optimizer=10,
            random_state=seed
        )
        
        bounds_transformer = SequentialDomainReductionTransformer(
            gamma_osc=0.8,
            gamma_pan=1.0
        )
        
        optimizer = BayesianOptimization(
            f=reward_function,
            pbounds=self.pbounds,
            random_state=seed,
            verbose=0,
            bounds_transformer=bounds_transformer
        )
        optimizer._gp = gpr
        
        return optimizer


    def decision(self, balls=None, my_targets=None, table=None):
        """ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æœç´¢æœ€ä½³å‡»çƒå‚æ•°
        
        å‚æ•°ï¼š
            balls: çƒçŠ¶æ€å­—å…¸ï¼Œ{ball_id: Ball}
            my_targets: ç›®æ ‡çƒIDåˆ—è¡¨ï¼Œ['1', '2', ...]
            table: çƒæ¡Œå¯¹è±¡
        
        è¿”å›ï¼š
            dict: å‡»çƒåŠ¨ä½œ {'V0', 'phi', 'theta', 'a', 'b'}
                å¤±è´¥æ—¶è¿”å›éšæœºåŠ¨ä½œ
        """
        if balls is None:
            print(f"[BasicAgent] Agent decisionå‡½æ•°æœªæ”¶åˆ°ballså…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚")
            return self._random_action()
        try:
            
            # ä¿å­˜ä¸€ä¸ªå‡»çƒå‰çš„çŠ¶æ€å¿«ç…§ï¼Œç”¨äºå¯¹æ¯”
            last_state_snapshot = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}

            remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
            if len(remaining_own) == 0:
                my_targets = ["8"]
                print("[BasicAgent] æˆ‘çš„ç›®æ ‡çƒå·²å…¨éƒ¨æ¸…ç©ºï¼Œè‡ªåŠ¨åˆ‡æ¢ç›®æ ‡ä¸ºï¼š8å·çƒ")

            # 1.åŠ¨æ€åˆ›å»ºâ€œå¥–åŠ±å‡½æ•°â€ (Wrapper)
            # è´å¶æ–¯ä¼˜åŒ–å™¨ä¼šè°ƒç”¨æ­¤å‡½æ•°ï¼Œå¹¶ä¼ å…¥å‚æ•°
            def reward_fn_wrapper(V0, phi, theta, a, b):
                # åˆ›å»ºä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿçš„æ²™ç›’ç³»ç»Ÿ
                sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
                sim_table = copy.deepcopy(table)
                cue = pt.Cue(cue_ball_id="cue")

                shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
                
                try:
                    if self.enable_noise:
                        V0_noisy = V0 + np.random.normal(0, self.noise_std['V0'])
                        phi_noisy = phi + np.random.normal(0, self.noise_std['phi'])
                        theta_noisy = theta + np.random.normal(0, self.noise_std['theta'])
                        a_noisy = a + np.random.normal(0, self.noise_std['a'])
                        b_noisy = b + np.random.normal(0, self.noise_std['b'])
                        
                        V0_noisy = np.clip(V0_noisy, 0.5, 8.0)
                        phi_noisy = phi_noisy % 360
                        theta_noisy = np.clip(theta_noisy, 0, 90)
                        a_noisy = np.clip(a_noisy, -0.5, 0.5)
                        b_noisy = np.clip(b_noisy, -0.5, 0.5)
                        
                        shot.cue.set_state(V0=V0_noisy, phi=phi_noisy, theta=theta_noisy, a=a_noisy, b=b_noisy)
                    else:
                        shot.cue.set_state(V0=V0, phi=phi, theta=theta, a=a, b=b)
                    
                    # å…³é”®ï¼šä½¿ç”¨å¸¦è¶…æ—¶ä¿æŠ¤çš„ç‰©ç†æ¨¡æ‹Ÿï¼ˆ3ç§’ä¸Šé™ï¼‰
                    if not simulate_with_timeout(shot, timeout=3):
                        return 0  # è¶…æ—¶æ˜¯ç‰©ç†å¼•æ“é—®é¢˜ï¼Œä¸æƒ©ç½šagent
                except Exception as e:
                    # æ¨¡æ‹Ÿå¤±è´¥ï¼Œç»™äºˆæå¤§æƒ©ç½š
                    return -500
                
                # ä½¿ç”¨æˆ‘ä»¬çš„â€œè£åˆ¤â€æ¥æ‰“åˆ†
                score = analyze_shot_for_reward(
                    shot=shot,
                    last_state=last_state_snapshot,
                    player_targets=my_targets
                )


                return score

            print(f"[BasicAgent] æ­£åœ¨ä¸º Player (targets: {my_targets}) æœç´¢æœ€ä½³å‡»çƒ...")
            
            seed = np.random.randint(1e6)
            optimizer = self._create_optimizer(reward_fn_wrapper, seed)
            optimizer.maximize(
                init_points=self.INITIAL_SEARCH,
                n_iter=self.OPT_SEARCH
            )
            
            best_result = optimizer.max
            best_params = best_result['params']
            best_score = best_result['target']

            if best_score < 10:
                print(f"[BasicAgent] æœªæ‰¾åˆ°å¥½çš„æ–¹æ¡ˆ (æœ€é«˜åˆ†: {best_score:.2f})ã€‚ä½¿ç”¨éšæœºåŠ¨ä½œã€‚")
                return self._random_action()
            action = {
                'V0': float(best_params['V0']),
                'phi': float(best_params['phi']),
                'theta': float(best_params['theta']),
                'a': float(best_params['a']),
                'b': float(best_params['b']),
            }

            print(f"[BasicAgent] å†³ç­– (å¾—åˆ†: {best_score:.2f}): "
                  f"V0={action['V0']:.2f}, phi={action['phi']:.2f}, "
                  f"Î¸={action['theta']:.2f}, a={action['a']:.3f}, b={action['b']:.3f}")
            return action

        except Exception as e:
            print(f"[BasicAgent] å†³ç­–æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚åŸå› : {e}")
            import traceback
            traceback.print_exc()
            return self._random_action()

class NewAgent(Agent):
    """
    Optimized NewAgent: Phase 23 - Black 8 Guardian
    æ”¹è¿›ç‚¹ï¼š
    1. æ–°å¢ 6æ¬¡æŠ—å™ªå®‰å…¨æ£€æŸ¥ï¼Œé˜²æ­¢è¯¯æ‰“é»‘8å’Œç™½çƒæ´—è¢‹ã€‚
    2. ç»§æ‰¿äº†ä¹‹å‰çš„èµ°ä½å’Œä¼˜åŒ–é€»è¾‘ã€‚
    """

    def __init__(self):
        super().__init__()
        self.BALL_RADIUS = 0.028575
        self.SEARCH_INIT = 15
        self.SEARCH_ITER = 10
        
        # åŒæ­¥ç¯å¢ƒçš„å™ªå£°å‚æ•°ï¼Œç”¨äºè‡ªæˆ‘è¯„ä¼°
        self.noise_std = {
            'V0': 0.1,      # é€Ÿåº¦æ ‡å‡†å·® 
            'phi': 0.1,     # è§’åº¦æ ‡å‡†å·®
            'theta': 0.1, 
            'a': 0.003, 
            'b': 0.003
        }
        print("[NewAgent] Phase 23: Black 8 Guardian å·²åˆå§‹åŒ– (å«6æ¬¡æŠ—å™ªæ£€æµ‹)")

    # ... [ä¿ç•™åŸæœ‰çš„ _distance, _normalize, _angle_to_phi, _calculate_ghost_ball ç­‰å·¥å…·å‡½æ•°] ...
    # ä¸ºäº†å®Œæ•´æ€§ï¼Œè¿™é‡Œåˆ—å‡ºå¿…é¡»çš„å·¥å…·å‡½æ•°ï¼Œæœªä¿®æ”¹çš„é€»è¾‘ä¿æŒåŸæ ·å³å¯
    
    def _distance(self, pos1, pos2):
        return np.linalg.norm(np.array(pos1[:2]) - np.array(pos2[:2]))

    def _normalize(self, vec):
        vec = np.array(vec[:2])
        norm = np.linalg.norm(vec)
        if norm < 1e-6: return np.array([1.0, 0.0])
        return vec / norm

    def _angle_to_phi(self, direction_vec):
        phi = np.arctan2(direction_vec[1], direction_vec[0]) * 180 / np.pi
        return phi % 360

    def _calculate_ghost_ball(self, target_pos, pocket_pos):
        target_to_pocket = self._normalize(np.array(pocket_pos[:2]) - np.array(target_pos[:2]))
        ghost_pos = np.array(target_pos[:2]) - target_to_pocket * (2 * self.BALL_RADIUS)
        return ghost_pos

    def _calculate_cut_angle(self, cue_pos, target_pos, pocket_pos):
        ghost_pos = self._calculate_ghost_ball(target_pos, pocket_pos)
        vec1 = self._normalize(np.array(ghost_pos) - np.array(cue_pos[:2]))
        vec2 = self._normalize(np.array(pocket_pos[:2]) - np.array(target_pos[:2]))
        dot = np.clip(np.dot(vec1, vec2), -1.0, 1.0)
        return np.degrees(np.arccos(dot))

    def _check_can_shoot_8(self, balls, original_targets):
        real_targets = [bid for bid in original_targets if bid != '8']
        remaining = [bid for bid in real_targets if balls[bid].state.s != 4]
        return len(remaining) == 0

    # ... [ä¿ç•™ _evaluate_position_quality, get_break_shot, _count_obstructions, _choose_best_target] ...
    # å‡è®¾è¿™äº›å‡½æ•°ä¸åŸæ–‡ä»¶ä¸€è‡´ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼Œé‡ç‚¹åœ¨ä¸‹é¢çš„éªŒè¯é€»è¾‘
    
    def _evaluate_position_quality(self, cue_pos, balls, my_targets, original_targets):
        # ... (ä¿æŒåŸä»£ç é€»è¾‘) ...
        # ç®€å•å®ç°ç”¨äºå ä½ï¼Œè¯·ä¿ç•™åŸæ–‡ä»¶å†…å®¹
        remaining_targets = [tid for tid in my_targets if balls[tid].state.s != 4]
        can_shoot_8 = self._check_can_shoot_8(balls, original_targets)
        if len(remaining_targets) == 0 or (len(remaining_targets) == 1 and remaining_targets[0] == '8' and not can_shoot_8):
            target_candidates = ['8']
        else:
            target_candidates = [t for t in remaining_targets if t != '8']
        if not target_candidates: return 1.0
        min_dist = 100.0
        for tid in target_candidates:
            dist = self._distance(cue_pos, balls[tid].state.rvw[0])
            if dist < min_dist: min_dist = dist
        if 0.2 < min_dist < 1.0: return 1.0
        return 0.5

    def get_break_shot(self, balls):
        target = balls['1']
        cue = balls['cue']
        vec = target.state.rvw[0] - cue.state.rvw[0]
        phi = self._angle_to_phi(self._normalize(vec))
        return {'V0': 8.0, 'phi': phi, 'theta': 0, 'a': 0.0, 'b': -0.2}
        
    def _count_obstructions(self, balls, from_pos, to_pos, exclude_ids=['cue']):
        # ... (ä¿æŒåŸä»£ç é€»è¾‘) ...
        count = 0
        line_vec = np.array(to_pos[:2]) - np.array(from_pos[:2])
        line_length = np.linalg.norm(line_vec)
        if line_length < 1e-6: return 0
        line_dir = line_vec / line_length
        for bid, ball in balls.items():
            if bid in exclude_ids or ball.state.s == 4: continue
            ball_pos = ball.state.rvw[0][:2]
            vec_to_ball = ball_pos - np.array(from_pos[:2])
            proj_length = np.dot(vec_to_ball, line_dir)
            if proj_length < 0 or proj_length > line_length: continue
            proj_point = np.array(from_pos[:2]) + line_dir * proj_length
            dist_to_line = np.linalg.norm(ball_pos - proj_point)
            if dist_to_line < self.BALL_RADIUS * 2.2: count += 1
        return count

    def _choose_best_target(self, balls, my_targets, table, original_targets):
        # ... (ä¿æŒåŸä»£ç é€»è¾‘) ...
        # è¯·ç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶ä¸­çš„ _choose_best_target å®ç°
        best_choice = None
        best_score = -1e9
        cue_pos = balls['cue'].state.rvw[0]
        can_shoot_8 = self._check_can_shoot_8(balls, original_targets)

        for target_id in my_targets:
            if target_id == '8' and not can_shoot_8: continue
            if balls[target_id].state.s == 4: continue
            target_pos = balls[target_id].state.rvw[0]
            for pocket_id, pocket in table.pockets.items():
                score = 0
                pocket_pos = pocket.center
                dist_cue_target = self._distance(cue_pos, target_pos)
                dist_target_pocket = self._distance(target_pos, pocket_pos)
                score += 50 / (1 + dist_cue_target + dist_target_pocket)
                cut_angle = self._calculate_cut_angle(cue_pos, target_pos, pocket_pos)
                if cut_angle > 80: continue
                score += (90 - cut_angle) * 1.2
                obs_1 = self._count_obstructions(balls, cue_pos, target_pos, exclude_ids=['cue', target_id])
                if obs_1 > 0: score -= 500
                obs_2 = self._count_obstructions(balls, target_pos, pocket_pos, exclude_ids=['cue', target_id])
                if obs_2 > 0: score -= 500
                ghost_pos = self._calculate_ghost_ball(target_pos, pocket_pos)
                for pid_danger, p_danger in table.pockets.items():
                    if self._distance(ghost_pos, p_danger.center) < 0.12: score -= 300
                if target_id == '8' and can_shoot_8: score += 500
                if score > best_score:
                    best_score = score
                    best_choice = (target_id, pocket_id)
        return best_choice

    def _geometric_shot(self, cue_pos, target_pos, pocket_pos):
        ghost_pos = self._calculate_ghost_ball(target_pos, pocket_pos)
        cue_to_ghost = ghost_pos - np.array(cue_pos[:2])
        phi = self._angle_to_phi(self._normalize(cue_to_ghost))
        dist = self._distance(cue_pos, ghost_pos)
        V0 = np.clip(1.8 + dist * 2.2, 1.5, 7.5)
        return {'V0': float(V0), 'phi': float(phi), 'theta': 0.0, 'a': 0.0, 'b': 0.0}

    def _optimized_search(self, geo_action, balls, my_targets, table, original_targets):
        # ... (ä¿æŒåŸä»£ç é€»è¾‘) ...
        # è¯·ç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶ä¸­çš„ _optimized_search å®ç°
        pbounds = {
            'V0': (max(0.5, geo_action['V0'] - 1.5), min(8.0, geo_action['V0'] + 1.5)),
            'phi': (geo_action['phi'] - 2.5, geo_action['phi'] + 2.5),
            'theta': (0, 0), 'a': (-0.5, 0.5), 'b': (-0.5, 0.5)
        }
        last_state = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
        can_shoot_8 = self._check_can_shoot_8(balls, original_targets)

        def reward_fn(V0, phi, theta, a, b):
            sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
            cue = pt.Cue(cue_ball_id="cue")
            shot = pt.System(table=copy.deepcopy(table), balls=sim_balls, cue=cue)
            try:
                shot.cue.set_state(V0=V0, phi=phi, theta=theta, a=a, b=b)
                pt.simulate(shot, inplace=True, max_events=200)
            except: return -500
            
            # æ­»é”ä¸åŸºç¡€åˆ†
            is_stuck = False
            for ball in shot.balls.values():
                if ball.state.s not in [0, 4]: is_stuck = True; break
            if is_stuck: return -2000
            base_score = analyze_shot_for_reward(shot, last_state, my_targets)
            if base_score < 0: return base_score
            
            new_pocketed = [bid for bid, b in shot.balls.items() if b.state.s == 4 and last_state[bid].state.s != 4]
            if '8' in new_pocketed and not can_shoot_8: return -1000
            
            own_pocketed = [bid for bid in new_pocketed if bid in my_targets]
            position_bonus = 0
            if len(own_pocketed) > 0 and '8' not in new_pocketed:
                final_cue_pos = shot.balls['cue'].state.rvw[0]
                pos_quality = self._evaluate_position_quality(final_cue_pos, shot.balls, my_targets, original_targets)
                position_bonus = pos_quality * 30
            return base_score + position_bonus

        try:
            optimizer = BayesianOptimization(f=reward_fn, pbounds=pbounds, random_state=42, verbose=0)
            optimizer.maximize(init_points=self.SEARCH_INIT, n_iter=self.SEARCH_ITER)
            if optimizer.max['target'] > -100:
                p = optimizer.max['params']
                return {'V0': p['V0'], 'phi': p['phi'], 'theta': p['theta'], 'a': p['a'], 'b': p['b']}
        except: pass
        return geo_action

    # ==================== æ–°å¢ï¼šæŠ—å™ªå®‰å…¨æ£€æŸ¥ ====================
    def _check_safety_robust(self, action, balls, table, can_shoot_8, simulations=6):
        """
        æ ¸å¿ƒæ”¹è¿›ï¼šé€šè¿‡å¤šæ¬¡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ£€æŸ¥åŠ¨ä½œçš„å®‰å…¨æ€§
        å¦‚æœä»»ä½•ä¸€æ¬¡æ¨¡æ‹Ÿå¯¼è‡´è¯¯è¿›é»‘8æˆ–ç™½çƒè¿›è¢‹ï¼Œåˆ™è§†ä¸ºä¸å®‰å…¨
        """
        for i in range(simulations):
            # 1. æ–½åŠ éšæœºå™ªå£° (æ¨¡æ‹ŸçœŸå®ç¯å¢ƒè¯¯å·®)
            noisy_action = {
                'V0': np.clip(action['V0'] + np.random.normal(0, self.noise_std['V0']), 0.5, 8.0),
                'phi': (action['phi'] + np.random.normal(0, self.noise_std['phi'])) % 360,
                'theta': np.clip(action['theta'] + np.random.normal(0, self.noise_std['theta']), 0, 90),
                'a': np.clip(action['a'] + np.random.normal(0, self.noise_std['a']), -0.5, 0.5),
                'b': np.clip(action['b'] + np.random.normal(0, self.noise_std['b']), -0.5, 0.5)
            }
            
            # 2. æ¨¡æ‹Ÿ
            sim_balls = {k: copy.deepcopy(v) for k, v in balls.items()}
            cue = pt.Cue(cue_ball_id="cue")
            shot = pt.System(table=copy.deepcopy(table), balls=sim_balls, cue=cue)
            try:
                shot.cue.set_state(**noisy_action)
                pt.simulate(shot, inplace=True, max_events=200)
            except:
                continue # ç‰©ç†å¼•æ“é”™è¯¯å¿½ç•¥ï¼Œä½†ä¸é€šè¿‡

            # 3. æ£€æŸ¥ç¾éš¾æ€§åæœ
            new_pocketed = [bid for bid, b in shot.balls.items() if b.state.s == 4 and balls[bid].state.s != 4]
            
            # [è‡´å‘½] ç™½çƒè¿›è¢‹ -> ç»å¯¹ç¦æ­¢
            if 'cue' in new_pocketed:
                return False
                
            # [è‡´å‘½] è¯¯è¿›é»‘8 -> ç»å¯¹ç¦æ­¢
            if '8' in new_pocketed and not can_shoot_8:
                return False
                
            # [å¯é€‰é«˜é˜¶] å¦‚æœé¦–çƒæ²¡æ‰“åˆ°ç›®æ ‡çƒï¼Œå¯èƒ½å¯¼è‡´çŠ¯è§„ï¼Œè¿™é‡Œä¸ºäº†è¿›æ”»æ€§å¯ä»¥æš‚æ—¶å®¹å¿ï¼Œ
            # ä½†å¦‚æœå¯¹çŠ¯è§„éå¸¸æ•æ„Ÿï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡Œ return False
            
        return True # æ‰€æœ‰æµ‹è¯•é€šè¿‡

    def _validate_and_adjust(self, action, balls, table, my_targets, original_targets):
        # éªŒè¯é›†ï¼šä¿ç•™åŸæœ‰çš„å¾®è°ƒé€»è¾‘ï¼Œä½†åŠ å…¥æ›´ä¸¥æ ¼çš„å™ªå£°è¿‡æ»¤
        variations = [
            (1.0, 0), (0.95, 0), (1.05, 0),
            (1.0, 0.5), (1.0, -0.5)
        ]
        sim_table = copy.deepcopy(table)
        can_shoot_8 = self._check_can_shoot_8(balls, original_targets)

        best_safe_action = None

        for v_scale, phi_offset in variations:
            test_action = action.copy()
            test_action['V0'] *= v_scale
            test_action['phi'] += phi_offset

            # 1. å…ˆè·‘ä¸€æ¬¡ç¡®å®šæ€§æ¨¡æ‹Ÿï¼ˆå¿«é€Ÿç­›é€‰ï¼‰
            sim_balls = {k: copy.deepcopy(v) for k, v in balls.items()}
            cue = pt.Cue(cue_ball_id="cue")
            shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
            shot.cue.set_state(**test_action)
            try:
                pt.simulate(shot, inplace=True, max_events=200)
            except:
                continue

            new_pocketed = [bid for bid, b in shot.balls.items() if b.state.s == 4 and balls[bid].state.s != 4]

            # åŸºç¡€è¿‡æ»¤
            if 'cue' in new_pocketed: continue
            if '8' in new_pocketed and not can_shoot_8: continue
            
            # 2. [æ”¹è¿›ç‚¹] æ ¸å¿ƒï¼š6æ¬¡æŠ—å™ªæµ‹è¯•
            # åªæœ‰é€šè¿‡äº†ç¡®å®šæ€§æµ‹è¯•çš„åŠ¨ä½œï¼Œæ‰æœ‰èµ„æ ¼è¿›å…¥æŠ—å™ªæµ‹è¯•ï¼ˆèŠ‚çœè®¡ç®—èµ„æºï¼‰
            if not self._check_safety_robust(test_action, balls, table, can_shoot_8, simulations=6):
                print(f"[Guardian] âš ï¸ æ‹¦æˆªäº†ä¸€ä¸ªé«˜é£é™©åŠ¨ä½œ (V0={test_action['V0']:.1f}, phi={test_action['phi']:.1f})")
                continue

            # 3. æ£€æŸ¥æ˜¯å¦è¿›ç›®æ ‡çƒ
            own_pocketed = [bid for bid in new_pocketed if bid in my_targets]
            if len(own_pocketed) > 0:
                return test_action # è¿™æ˜¯ä¸€ä¸ªæ—¢è¿›çƒåˆé²æ£’çš„åŠ¨ä½œ

            # 4. å¦‚æœæ²¡è¿›çƒä½†å®‰å…¨ï¼Œå­˜ä¸ºå¤‡é€‰
            if v_scale == 1.0 and phi_offset == 0:
                best_safe_action = test_action

        # å¦‚æœæ‰€æœ‰è¿›æ”»çº¿è·¯éƒ½ä¸å®‰å…¨ï¼ˆé€šä¸è¿‡æŠ—å™ªæµ‹è¯•ï¼‰ï¼Œæˆ–è€…æ‰“ä¸è¿›çƒ
        if best_safe_action is not None:
            return best_safe_action

        # å…œåº•é˜²å®ˆ
        print("[Protector] ğŸ›¡ï¸ å¯åŠ¨é˜²å®ˆæ¨¡å¼")
        return self._defense_shot(balls, my_targets)

    def _defense_shot(self, balls, my_targets):
        # ... (ä¿æŒåŸä»£ç é€»è¾‘) ...
        # è¯·ç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶ä¸­çš„ _defense_shot å®ç°
        cue_pos = balls['cue'].state.rvw[0]
        min_dist = 100
        target_id = None
        candidates = [b for b in my_targets if balls[b].state.s != 4]
        if not candidates: candidates = ['8']
        for tid in candidates:
            dist = self._distance(cue_pos, balls[tid].state.rvw[0])
            if dist < min_dist:
                min_dist = dist
                target_id = tid
        if target_id:
            vec = balls[target_id].state.rvw[0] - cue_pos
            phi = self._angle_to_phi(self._normalize(vec))
            return {'V0': 1.0 + min_dist, 'phi': phi, 'theta': 0, 'a': 0, 'b': 0}
        return self._random_action()

    def decision(self, balls, my_targets, table):
        # ... (ä¿æŒåŸä»£ç é€»è¾‘) ...
        try:
            balls_on_table = [b for k, b in balls.items() if k != 'cue' and b.state.s != 4]
            if len(balls_on_table) == 15:
                print("[NewAgent] ğŸ± å¼€çƒ")
                return self.get_break_shot(balls)

            original_targets = list(my_targets)
            remaining = [bid for bid in my_targets if balls[bid].state.s != 4]
            if not remaining: my_targets = ['8']

            choice = self._choose_best_target(balls, my_targets, table, original_targets)
            if not choice: return self._defense_shot(balls, my_targets)

            tid, pid = choice
            cue_pos = balls['cue'].state.rvw[0]
            target_pos = balls[tid].state.rvw[0]
            pocket_pos = table.pockets[pid].center
            
            print(f"[NewAgent] ç›®æ ‡: {tid} -> è¢‹å£: {pid}")

            geo_action = self._geometric_shot(cue_pos, target_pos, pocket_pos)
            final_action = self._optimized_search(geo_action, balls, my_targets, table, original_targets)
            final_action = self._validate_and_adjust(final_action, balls, table, my_targets, original_targets)
            return final_action

        except Exception as e:
            print(f"[NewAgent] Critical Error: {e}")
            import traceback
            traceback.print_exc()
            return self._random_action()